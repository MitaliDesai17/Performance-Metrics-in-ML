# Performance-Metrics-in-ML

Performance metrics in machine learning are measurements used to evaluate the effectiveness and accuracy of a machine learning model. These metrics quantify how well the model performs in predicting outcomes compared to actual values. The following performance metrics are included:

1. **Accuracy:** Measures the proportion of correctly predicted instances out of the total instances evaluated. It is suitable for balanced datasets but can be misleading with imbalanced datasets.

2. **Precision:** Indicates the proportion of true positive predictions among all positive predictions made by the model. It focuses on minimizing false positives.

3. **Recall (Sensitivity or True Positive Rate):** Measures the proportion of true positive instances that were correctly predicted by the model out of all actual positive instances. It focuses on minimizing false negatives.

4. **F1 Score:** Harmonic mean of precision and recall. It provides a single score that balances both precision and recall, useful when there is an uneven class distribution.

5. **Confusion Matrix:** Table that summarizes the performance of a classification model. It shows the number of true positives, true negatives, false positives, and false negatives.

6. **Mean Absolute Error (MAE):** Average of the absolute differences between predicted and actual values. It measures the average magnitude of errors in a set of predictions.

7. **Mean Squared Error (MSE):** Average of the squared differences between predicted and actual values. It penalizes larger errors more heavily, making it sensitive to outliers.

8. **R-squared (Coefficient of Determination):** Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where 1 indicates perfect predictions.

These metrics help data scientists and machine learning practitioners assess and compare different models to select the best-performing one for a specific task or problem domain.
